<?xml version="1.0" encoding="utf-8"?>

<feed xmlns="http://www.w3.org/2005/Atom" >
  <generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator>
  <link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" />
  <link href="http://localhost:4000/" rel="alternate" type="text/html" />
  <updated>2023-09-28T15:56:37-07:00</updated>
  <id>http://localhost:4000/</id>

  
    <title type="html">Data Engineer</title>
  

  
    <subtitle>Hi. This is my site where i can showcase my work and expertise in the data engineering field. I have 5 Years of experience and always looking to expand my skillset!</subtitle>
  

  

  
  
    <entry>
      <title type="html">Project 1</title>
      <link href="http://localhost:4000/" rel="alternate" type="text/html" title="Project 1" />
      <published>2023-09-20T00:00:00-07:00</published>
      <updated>2023-09-20T00:00:00-07:00</updated>
      <id>http://localhost:4000/project-1</id>
      <content type="html" xml:base="http://localhost:4000/">&lt;h1 id=&quot;aws-lambda-function-earthquake-dashboard-pipeline&quot;&gt;AWS Lambda Function: Earthquake Dashboard Pipeline&lt;/h1&gt;

&lt;iframe src=&quot;https://public.tableau.com/views/earthquakes_16956986619940/Dashboard1?:showVizHome=no&amp;amp;:embed=true&quot; width=&quot;800&quot; height=&quot;400&quot; value=&quot;:original_view=yes&quot;&gt;&lt;/iframe&gt;

&lt;h2 id=&quot;overview&quot;&gt;Overview&lt;/h2&gt;

&lt;p&gt;This AWS Lambda function is designed to automate the process of fetching earthquake data from the USGS Earthquake Catalog, transforming it into a suitable format, and then upserting (inserting or updating) the data into a MySQL database table. The function also ensures that duplicate data is not inserted into the database.&lt;/p&gt;

&lt;h2 id=&quot;steps&quot;&gt;Steps&lt;/h2&gt;

&lt;p&gt;Here’s a detailed breakdown of what the Lambda function does:&lt;/p&gt;

&lt;h2 id=&quot;step-1-data-retrieval&quot;&gt;Step 1: Data Retrieval&lt;/h2&gt;
&lt;p&gt;The Lambda function starts by retrieving earthquake data from the USGS Earthquake Catalog. It fetches the data in CSV format using an HTTP GET request.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;earthquake_url = &apos;https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/2.5_day.csv&apos;
s = requests.get(earthquake_url).content
earthquake_df = pd.read_csv(io.StringIO(s.decode(&apos;utf-8&apos;)))


&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;step-2-data-transformation&quot;&gt;Step 2: Data Transformation&lt;/h1&gt;

&lt;p&gt;The fetched data is converted into a Pandas DataFrame, making it easier to work with. Additionally, a new column called ‘hash_column’ is created in the DataFrame by combining all other columns and hashing the resulting string using SHA-256.&lt;/p&gt;

&lt;h1 id=&quot;step-3-data-preprocessing&quot;&gt;Step 3: Data Preprocessing&lt;/h1&gt;
&lt;p&gt;Any NaN (Not a Number) values in the DataFrame are filled with ‘0.00’ to ensure consistency.&lt;/p&gt;

&lt;h1 id=&quot;step-4-data-type-mapping&quot;&gt;Step 4: Data Type Mapping&lt;/h1&gt;
&lt;p&gt;A mapping of Pandas data types to MySQL data types is defined to facilitate the subsequent database interaction.&lt;/p&gt;

&lt;h1 id=&quot;step-5-database-connection&quot;&gt;Step 5: Database Connection&lt;/h1&gt;
&lt;p&gt;The Lambda function establishes a connection to a MySQL database using environment variables for the database endpoint, username, and password.&lt;/p&gt;

&lt;h1 id=&quot;step-6-check-for-existing-data&quot;&gt;Step 6: Check for Existing Data&lt;/h1&gt;
&lt;p&gt;An SQL query is executed to retrieve hash values from an existing MySQL table in the “portfolio” database. These hash values represent the data that is already present in the database.&lt;/p&gt;

&lt;h1 id=&quot;step-7-data-upsert&quot;&gt;Step 7: Data Upsert&lt;/h1&gt;
&lt;p&gt;The function then identifies new records in the DataFrame by comparing the hash values in the DataFrame with the retrieved hash values from the MySQL table. It filters the DataFrame to keep only the new records that are not present in the MySQL table.&lt;/p&gt;

&lt;h1 id=&quot;step-8-data-insertion&quot;&gt;Step 8: Data Insertion&lt;/h1&gt;
&lt;p&gt;SQL INSERT statements are dynamically generated based on the data types and column names obtained earlier. The Lambda function iterates through the filtered DataFrame and inserts the new records into the MySQL table.&lt;/p&gt;

&lt;h1 id=&quot;step-9-response&quot;&gt;Step 9: Response&lt;/h1&gt;
&lt;p&gt;Finally, the Lambda function returns a JSON response indicating the status of execution. If the function completes successfully, it returns a status code of 200 and a message of “Done.” If an exception occurs, it returns a status code of 404 along with an error message.&lt;/p&gt;

&lt;p&gt;This Lambda function streamlines the process of acquiring earthquake data and ensuring that it’s efficiently upserted into a MySQL database, maintaining data integrity and avoiding duplicate entries. It serves as an example of automation and data synchronization in a serverless environment.&lt;/p&gt;

&lt;h1 id=&quot;code&quot;&gt;Code&lt;/h1&gt;

&lt;p&gt;You Can find the full code &lt;a href=&quot;https://github.com/Nicholasphom/Nicholasphom.github.io/blob/main/PortfolioCode/Project1/lambda_function.py&quot;&gt;Here&lt;/a&gt;&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name></name>
        
        
      </author>

      
        <category term="ETL Pipeline/BI" />
      

      

      
        <summary type="html">AWS Lambda Function: Earthquake Dashboard Pipeline</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Project 2</title>
      <link href="http://localhost:4000/" rel="alternate" type="text/html" title="Project 2" />
      <published>2023-07-17T00:00:00-07:00</published>
      <updated>2023-07-17T00:00:00-07:00</updated>
      <id>http://localhost:4000/project-2</id>
      <content type="html" xml:base="http://localhost:4000/">&lt;h1 id=&quot;docker-compose-for-hadoop-spark-and-airflow&quot;&gt;Docker Compose for Hadoop, Spark, and Airflow&lt;/h1&gt;
&lt;p&gt;This Docker Compose configuration is designed to set up a development environment for Hadoop, Spark, and Apache Airflow. It orchestrates various services and containers, making it easier to run and manage these components together.
This is meant for you to run a sanitized develop enviorment and is a work in progress
You can find the repo &lt;a href=&quot;https://github.com/Nicholasphom/datapipeline-docker/tree/master&quot;&gt;here&lt;/a&gt;&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name></name>
        
        
      </author>

      
        <category term="Docker/Cloud Architect" />
      

      

      
        <summary type="html">Docker Compose for Hadoop, Spark, and Airflow This Docker Compose configuration is designed to set up a development environment for Hadoop, Spark, and Apache Airflow. It orchestrates various services and containers, making it easier to run and manage these components together. This is meant for you to run a sanitized develop enviorment and is a work in progress You can find the repo here</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Project 3</title>
      <link href="http://localhost:4000/" rel="alternate" type="text/html" title="Project 3" />
      <published>2014-07-16T00:00:00-07:00</published>
      <updated>2014-07-16T00:00:00-07:00</updated>
      <id>http://localhost:4000/project-3</id>
      <content type="html" xml:base="http://localhost:4000/">&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;In this project I explored the idea of building serverless resources to host notebooks to run etl jobs on to export to bigquery.
From there i was able to build visualizations on Dekart and Tableau(Not shown)&lt;/p&gt;

&lt;h1 id=&quot;notebook&quot;&gt;Notebook&lt;/h1&gt;

&lt;h1 id=&quot;visualizations&quot;&gt;Visualizations&lt;/h1&gt;

&lt;p&gt;You can see the map &lt;a href=&quot;../img/portfolio/Accidents.html&quot;&gt;Here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Warning, It is big&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name></name>
        
        
      </author>

      
        <category term="Web Development" />
      

      

      
        <summary type="html">Introduction</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Project 4</title>
      <link href="http://localhost:4000/" rel="alternate" type="text/html" title="Project 4" />
      <published>2014-07-15T00:00:00-07:00</published>
      <updated>2014-07-15T00:00:00-07:00</updated>
      <id>http://localhost:4000/project-4</id>
      <content type="html" xml:base="http://localhost:4000/">&lt;h1 id=&quot;tbd&quot;&gt;TBD&lt;/h1&gt;</content>

      
      
      
      
      

      <author>
          <name></name>
        
        
      </author>

      
        <category term="TBD" />
      

      

      
        <summary type="html">TBD</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Project 6</title>
      <link href="http://localhost:4000/" rel="alternate" type="text/html" title="Project 6" />
      <published>2014-07-15T00:00:00-07:00</published>
      <updated>2014-07-15T00:00:00-07:00</updated>
      <id>http://localhost:4000/project-6</id>
      <content type="html" xml:base="http://localhost:4000/">&lt;h1 id=&quot;tbd&quot;&gt;TBD&lt;/h1&gt;</content>

      
      
      
      
      

      <author>
          <name></name>
        
        
      </author>

      
        <category term="TBD" />
      

      

      
        <summary type="html">TBD</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Project 5</title>
      <link href="http://localhost:4000/" rel="alternate" type="text/html" title="Project 5" />
      <published>2014-07-14T00:00:00-07:00</published>
      <updated>2014-07-14T00:00:00-07:00</updated>
      <id>http://localhost:4000/project-5</id>
      <content type="html" xml:base="http://localhost:4000/">&lt;p&gt;# TBD&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name></name>
        
        
      </author>

      
        <category term="TBD" />
      

      

      
        <summary type="html"># TBD</summary>
      

      
      
    </entry>
  
</feed>
